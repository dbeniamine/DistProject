\documentclass[a4paper]{article}
\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{listings}

\lstset{basicstyle=\footnotesize,breaklines=true}

%%clickable links
\usepackage{hyperref}
\hypersetup{
    colorlinks=true, %colore les liens
    breaklinks=true, %permet le retour à la ligne dans les liens trop longs
    urlcolor= blue, %couleur des hyperliens
    linkcolor= black, %couleur des liens internes
}
%formatted algorithm:
\usepackage{algpseudocode}
\usepackage{algorithm}

\algblockdefx[Event]{Event}{EndEvent}%
[1][]{\textbf{Upon event :} #1}%
{}

\algblockdefx[Data]{Data}{EndData}%
[1][]{\textbf{Data :}}%
{}


\algblockdefx[Init]{Init}{EndInit}%
[1][]{\textbf{Initialization :}}%
{}


%% New commands
\newcommand{\eqdef}{\;\stackrel{\text{def}}{=}\;}

\begin{document}
\title{Distributed Systems: Network Simulator}
\author{David Benamine \& Rodolphe Lepigre\\ MOSIG - Parallel, Distributed and Embedded Systems}

\date{\today}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Introduction}
As part of our Distributed Network class, we had to build a network simulator
tool and use it to implement and experiment with various broadcast protocols.
In particular we paid much attention to the latency and throughput offered by
the considered protocols.

This report and the source files of the project are both part of our answer to
the problem. The source files should be globally well documented, but reading
this report should help the reader to better understand the structure of the
program.\\

\noindent\textbf{Structure of the report:} In the first section we present the
architecture and functionalities of our simulator. We also present the results
of some tests that we performed to check the behaviour of the system using the
broadcast protocols seen in class (Basic, Tree and Pipe-line broadcast).

In the second and third sections we present two regular total-order broadcast
protocols. The first one achieves a good latency (time for a broadcast to be
achieved with only one process sending), and the second one has a good
throughput when all process are sending at the same time. We also give a
detailed theoretical analysis of the two protocols.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The network simulator}
In this section we describe the architecture of the network simulator that we
programmed using the C programming language. The simulator follows a round
based approach and makes use of only one thread, as was part of its
specification.

\subsection{Basic principle and usage}
Before diving into a detailed description of the architecture of the program,
we will start by giving some hints on how to use the simulator, and also try
to provide some intuition to the reader on its basic working principles.

Let us first outline some useful terminology that we will use throughout this
report. In our simulator, a single machine capable of sending a message to
other machines will be called a \textit{process}, a \textit{node}, or simply
a \textit{machine}. The term \textit{external event} will refer to any action
taken by the user of the simulator. For example, at some point the user might
decide that a node should initiate a broadcast. This information will be
passed using an external event.

Before being able to use the simulator, the user should first compile it. A
\textit{makefile} is provided in the source directory \textit{src/}. It is
considered that the user is runing a \textit{POSIX}-friendly operating system
and that the regular building tools are present on his machine (\textit{gcc},
\textit{make},...).
\begin{lstlisting}
> cd src/
> make
\end{lstlisting}

Once the program has been (successfully) compiled, an executable file should
have appeared in the source directory. The program contains a ``help'' section
which can be accessed in a standard manner.
\begin{lstlisting}
> ./Broadcast -h
Usage: ../src/Broadcast [-N n][-R n][-h][-b|t|i|p]
Possible arguments:
-N n	Specify a number of nodes n, default is 4.
-R n	Specify a number of rounds n, default is 20.
-h	Display this help message.
Selection of broadcast mode:
-i	IP broadcast (default).
-b	Basic broadcast.
-t	Tree broadcast.
-p	Pipeline broadcast.
-L	Total order broadcast with good latency.
-T	Total order broadcast with good throughput.
\end{lstlisting}

The behaviour of the program can be changed using the command line arguments
as hinted by the ``help'' section content. In particular, the number of nodes
used during the simulation can be set. Also the number of rounds to run can be
set, and if it is set to $0$ the system will run forever.

The broadcast protocol that is going to be used can be selected as well from
the command line. The available options are the following.
\begin{itemize}
    \item IP broadcast: use multicast.
    \item Basic broadcast: the broadcaster sends to every other node in turn
        (one per round).
    \item Pipeline broadcast: the broadcaster sends the message to its neighbour
        which sends it to its neighbour and so on.
    \item Total order broadcast with good latency (see section
        \ref{sec:latencyTO}).
    \item Total order broadcast with good throughput (see section
        \ref{sec:throughputTO}).
\end{itemize}

Once the program is run, the simulation starts right away. At each turn, the
user will be prompted to enter external events for the system. Any number of
external event can be entered at the begining of each round. External read on
the standard input (on by line). And when the user is done sending events, he
simply types ``start'' for the simulator to do a round. The format for the
external events is
\begin{lstlisting}
id event
\end{lstlisting}
where ``id'' is an integer (between 0 and the number of nodes) which is the identifier of the node to which the
event is destined. ``event'' is the content of the event passed to the
node which can be an
arbitrary string (with no line break).
% TODO Give the events that are built-in

\subsection{Architecture of the system}
In order to better understand how the source code is organized, we give a
brief description of the content of every source file.
\begin{itemize}
    \item \textit{List.h} define the structure List used by
        \textit{Fifo.$<$c/h$>$} and
        \textit{SortedList.$<$c/h$>$}
    \item \textit{SortedList.h} contains a small library providing sorted list of
        objects. This library can be used by the nodes to store and sort
        their messages.
    \item \textit{SortedList.c} implements the functions defined in
        \textit{SortedList.h}
    \item \textit{Fifo.h} contains a small library providing queues. These are
        used to store pending messages of external events for each process.
        It seems fair for messages (resp. external events) to be sent (resp.
        treated) in the order they arrived in the system (FIFO order: First
        In, First Out).
    \item \textit{Fifo.c} implements the functions defined in \textit{Fifo.h}.
    \item \textit{Message.h} defines what messages (a sender, a receiver and the
        content) and provides functions to initialize, delete and copy
        messages.
    \item \textit{Message.c} implements the functions defined in
        \textit{Message.h}.
    \item \textit{Broadcast.h} contains a definition of the different broadcast
        protocols.
    \item \textit{Broadcast.c} implements all the different broadcast protocols.
    \item \textit{Simulator.h} defines the core functions and data structures
        of the simulator accessible by the nodes or the main function. In particular the function \textit{LaunchSimulation}
        is the core function of the simulator and contains the main loop which
        will do the rounds, read external events and apply the broadcast
        policies defined in \textit{Broadcast.h}.
    \item \textit{Simulator.c} defines the internal structure of the
        simulator and implements the functions defined in
        \textit{Simulator.h}.
    \item \textit{Main.c} contains the main function of the program. It takes
        care of the command line arguments, initialize the system and call
        the \textit{LaunchSimulation} function.
\end{itemize}
% TODO Explain how node functions work and detail what LaunchSimulation does
\subsection{How to write a program using the simulator}
Writing a node using our simulator is quite easy, you just have to 
include the file Simulator.h and write a function :\\
\textit{void myProtocol(int id, Message m)}

This function will be run by each node at each round of the execution.\\
id is the unique identifier of the Node, and m is either NULL or the
message received by the node id at the beginning of the round.\\
A node can interact with the systems using the functions defined in
\textit{Simulator.h} and \textit{Message.h}. For instance to get an external event
(if there is any) one can use the function \textit{readExternalEvents},
nodes can also send messages to the others and get the total number of
nodes in the system. Least but not last, if your nodes needs some
persistent data, you just have to define a data structure like this:\\
\begin{verbatim}
typedef struct _NodesData{
    int clock;
    SortedList pending;
}*NodesData;
\end{verbatim}
During the first round, you will have to tell the simulator that you
have some data to store for your nodes using the function \textit{void *setData(int id,
void *data)}.Than you can retrieve these data at anytime using the function
\textit{void *getData(int id)}.

Once your protocol is ready, the only thing you have to do is to create
a Main and call the function \textit{initSystem(int nb\_nodes, int
nb\_rounds, NodesFct fun)}, then you can finally start the simulation
with \textit{LaunchSimulation()}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{A regular total-order broadcast protocols with good latency}
\label{sec:latencyTO}

This first protocol makes use or the tree broadcast protocol since it achieves
an optimal latency of $log(n)$. In order to obtain a total-order, i.e.
guarantee that any two process will deliver messages in the exact same order,
we use one of the nodes as a relay. More precisely, when a node wishes to
perform a broadcast, it sends the message to the relay node which will
broadcast the message on its behalf.

Intuitively, any node in the tree will receive the messages in the same order
since the same tree traversal scheme will be used for each message. When a
node of the tree receives a broadcasted message, it can deliver it immediatly
before forwarding it.

Since the messages to be broadcasted need to be sent to the relay node, the
achieved latency should be equal to the latency of the tree broadcast plus
the time required to unicast a message (which is $1$ round). Hence, the
latency of this protocol should intuitively be $log(n) + 1$ rounds.

\subsection{Algorithm}
\begin{algorithm}[H]
    \centering
    \begin{algorithmic}[5]
        \Data
        \State int[][] Children
        \Comment{Ordered list of the childrens of each nodes}
        \EndData
        \Init
        \For{n in AllNodes()}
        \State Children[n]$\gets\{(2n + 1)2^i | i \in \mathbb{N}\} \cap \text{AllNodes()}$
        \Comment{Children[n] is sorted in increasing order}
        \EndFor
        \EndInit
        \Event $< tob,Broadcast\ |\ m> $
        \Comment{Start a broadcast}
        \If{Id()==0}
        \Comment{If the broadcaster is the relay}
        \State Deliver(0,m)
        \Comment{It can deliver}
        \For{c in Children[0]}
        \Comment{And forward the message}
        \State Send(c,$<m,0>$)
        \EndFor
        \Else
        \Comment{Otherwise ask the relay to forward}
        \State Send(0,$<m,Id()>$)
        \EndIf
        \EndEvent

        \Event $<Receive\ | <m,broadcaster>>$
        \State Deliver(broadcaster,m)
        \Comment{Deliver on right away}
        \For{c in Children[Id()]}
        \Comment{And forward the message}
        \State Send(c,$<m,broadcaster>$)
        \EndFor
        \EndEvent
    \end{algorithmic}
    \caption{Tree-based total ordered broadcast protocol}
\end{algorithm}

\subsection{Theoretical analysis}
\subsubsection*{Correctness}
\begin{itemize}
    \item Validity: we assume that there are no crashes, so if a process $p$
        broadcasts a message $p$, then $p$ eventually delivers $m$. If $p = 0$
        ($p$ is the relay node) the proof is trivial (by definition of the
        \textit{Broadcast} event).

        If $p$ is not the relay, the message $m$ will be forwarded to the
        relay for it do perform the broadcast. Since the broadcast is
        propagated on a tree which root is the relay, any node in the tree
        will eventually deliver the message (by definition of the
        \textit{Receive} event). In particular $p$ will eventually deliver it.
    \item No duplication: when a message is broadcasted by a node $p$ it is not
        delivered right away by $p$ (except if $p = 0$). A node $p$ only
        delivers a message $m$ when it receives it from its parent node (by
        definition of the \textit{Receive} event). By the property that no
        node in a tree can have more than one parent, a message can only be
        delivered once.
    \item No creation: delivery of messages $m$ by a process $p$ happen in two
        cases. Either during a \textit{Broadcast} event if $p=0$, or during a
        \textit{Receive} event.

        In the first case, the message $m$ is delivered by process $p=0$, which
        initiated itself a broadcast (the message $m$ was previously
        broadcasted by process $p=0$).

        In the second case, the message $m$ is deliverd by $p$ in response of
        a \textit{Receive} event. As we are using a perfect point-to-point
        link (with in particular no creation), the message was sent by the
        parent of the node, which received it before by its parent and so on
        up to the root of the tree, which is process $0$. There are two
        possibilities: either $0$ is the broadcaster, or not. In the first
        case $0$ previously initiated the broadcast. In the second case, some
        other process $s$ initiated the broadcast and sent its message to the
        relay (by definition of the \textit{Broadcast} event).
    \item Agreement: since all process are correct (no crashes) we need to
        show that when a message $m$ is delivered by a process $p$ then it is
        eventually delivered by every other process. Processes are organized
        in a tree which root is process $0$, so process $p$ has related nodes
        in the tree: a parent if $p \neq O$, siblings and childrens.

        If $p \neq 0$, his parent should have delivered message $m$ before
        $p$ since the message was forwarded to $p$ by its parent.

        If $p$ has siblings (nodes that share the same parent as $p$), the
        parent should take care of forwarding the message to them, and the
        message will be properly delivered in the sibling branches of the
        tree independently of whan happen for $p$.

        If $p$ has children it will eventually forward message $m$ to them
        (by definition of the \textit{Receive} event) so that they can
        deliver it and forward it in turn to their children and so on.
    \item Total order: all the messages are effectively broadcasted by process
        $0$ (the relay) since no delivery happens until process $0$ receives
        the message to broadcast. Once process $0$ has chosen an order for the
        messages to be delivered, the order of delivery is kept throughout the
        tree. Since every node has only one parent and the link between this
        node and its parent is fifo, there can be no inversion. Also when a
        node forwards a message to its children it sends this message to all
        of his children without interspering other messaging during the
        process. This ensures a total order for the delivery of messages.
\end{itemize}

\subsubsection*{Latency}
The algorithm is based on the tree-broadcast protocol seen in class. This
protocol has a latency of $\lceil\log_2(N)\rceil$ where $N$ is the number of
nodes.

The protocol presented in this section makes use of the tree-broadcast
protocol by having a node called the relay broadcast all the messages on
behalf of all the nodes of the system (and in particular itself).

When the relay originates a broadcast, the latency is that of the tree
broadcast protocol, i.e $\lceil\log_2(N)\rceil$. However, when a node that is
not the relay wished to broadcast a message, it first needs to unicast the
message to the relay, which take one round. The latency is then
$\lceil\log_2(N)\rceil + 1$.

We give two different results for the latency:
\begin{itemize}
    \item \textbf{Worst case latency:} $\lceil\log_2(N)\rceil + 1$
    \item \textbf{Mean latency:} $\frac{1}{N} \lceil\log_2(N)\rceil +
        \frac{N-1}{N} (\lceil\log_2(N)\rceil + 1)
        = \lceil\log_2(N)\rceil + \frac{N-1}{N}$
\end{itemize}

Both the worst case and the mean latency tend to the optimal when $N$ is
large.

\subsubsection*{Throughput}
Let's consider a system with $N$ nodes that wishes to broadcast a message
concurently. We wish to know how long this will take to all $N$ broadcasts
to complete.

At the first stem, the relay only knows of the message it wishes to broadcast
so it starts to broadcast it. After $\lceil\log_2(N)\rceil$ steps, the relay's
broadcast is completed.

In the mean time, the relay has been sending data but has had plenty of time
to receive the data to broadcast from one of the other nodes. The second tree
broadcast from $0$ can hence start right away, and is completed after
$\lceil\log_2(N)\rceil$ steps.

By reasoning in the same way we can see that it takes $N \lceil\log_2(N)\rceil$
rounds to complete the $N$ broadcasts. This gives us the throughput of the
system which is equal to $\frac{1}{\lceil\log_2(N)\rceil}$.

The throughput tends slowly to $0$ when $N$ grows large, which is quite bad.

\subsection{Empirical analysis}
% TODO

\subsubsection*{Latency}
% TODO

\subsubsection*{Throughput}
% TODO

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{A regular total-order broadcast protocols with good throughput}
\label{sec:throughputTO}

This protocol is based on the pipeline broadcast protocol but as soon as a node
receives a message, it will add it to a sorted list. A node $p$ can only deliver the
first message of its list if this message have been acknowledged by the
successor of $p$ in the pipeline or if $p$ is the last node of the pipeline.
This acknowledgement system ensure the total order property (see section
\ref{sec:pipelineack-proof}).
\subsection{Algorithm}
\begin{algorithm}[H]
    \centering
    \begin{algorithmic}[5]
        \Data
        \State int : clk
        \Comment{A logical clock}
        \State int : next
        \Comment{the id of the next process in the pipeline}
        \State int : prec
        \Comment{the id of the previous process in the pipeline}
        \State Pending : OrderedList
        \Comment{A list ordered by clock then id}
        \EndData
        \Init
        \State clk$\gets$0
        \State next$\gets$Id()+1\%NProcess
        \If{Id()=0}
        \State prec$\gets$NProcess
        \Else
        \State prec$\gets$Id()-1
        \EndIf
        \State Pending$\gets$EmptyQueue
        \EndInit
        \Event $< tob,Broadcast\ |\ m> $
        \Comment{Start a broadcast}
        \State clk++;
        \State Pending$\rightarrow$add($<m,Id(), clk, false>$) 
        \Comment{The message is added\\}
        \Comment{to the list the false boolean\\}
        \Comment{indicate that we have to wait for one ack}
        \State Send(next,$<m,Id(),clk>$)
        \EndEvent
        \Event $<Receive\ | <m,sender, mclk>>$
        \State clk$\gets$MAX(clk, mclk)+1
        \If{next=sender}
        \State Pending$\rightarrow$add($<m,sender,mclk,true>$)
        \Comment{We are at the end\\}
        \Comment{of the pipeline}
        \State Send(prec,$<ack,sender,mclk>$)
        \Comment{so we start the\\}
        \Comment{broadcast of acks}
        \If{Pending$\rightarrow$IsHead(sender,mclk)}
        \State Pending$\rightarrow$RemoveHead()
        \Comment{m is the first message of\\}
        \Comment{the queue, we can deliver it}
        \State Deliver(sender,m)
        \Comment{And deliver it}
        \EndIf
        \Else
        \State Pending$\rightarrow$add($<m,sender,mclk,false>$)
        \State Send(next,$<m,sender,mclk>$)
        \Comment{We forward m through the pipeline}
        \EndIf
        \EndEvent
        \algstore{myalg}
    \end{algorithmic}
    \caption{Pipeline based total ordered broadcast protocol}
\end{algorithm}
\begin{algorithm}[H]
    \centering
    \begin{algorithmic}[5]
        \algrestore{myalg}

        \Event $<Receive\  | <ack,sender, mclk>>$
        \State clk$\gets$ Max(clk,mlck)+1
        \If{sender$\neq$Id()}
        \Comment{We have to forward the ack}
        \State Send(prec,$<ack,sender,mclk>$
        \EndIf
        \If{Pending$\rightarrow$IsHead(sender,mclk)}
        \Comment{m is the head\\}
        \Comment{we can deliver it}
        \State m$\gets$(Pending$\rightarrow$RemoveHead())
        \State Deliver(sender,m)
        \State $<m,sender,mclk,b>\gets$Pending$\rightarrow$getHead()
        \While{b}
        \Comment{While we have receive an ack for\\}
        \Comment{the message at the head of the queue\\}
        \Comment{we can deliver it}
        \State Pending$\rightarrow$RemoveHead()
        \State Deliver(sender,m)
        \State $<m,sender,mclk,b>\gets$(Pending$\rightarrow$getHead())
        \EndWhile
        \Else
        \Comment{m isn't the head we mark m as acknowledged\\}
        \Comment{but deliver it until m is the head\\}
        \Comment{of the pending queue}
        \State Pending$\rightarrow$Remove($<m,sender,mclk,false>$)
        \State Pending$\rightarrow$Add($<m,sender,mclk,true>$)
        \EndIf
        \EndEvent
    \end{algorithmic}
\end{algorithm}


\subsection{Theoretical analysis}
\subsubsection{Correctness}
\begin{itemize}
    \item Validity: As there  is no crashes, if a process P broadcast a
        message m, m will be received, put in the pending queue and acknowledged 
        by every process. When P will receive the ack for m, either m will be
        the head of it's queue and he will be able to deliver it, or P will wait
        for at least one other message ack. 
        
        As the queue is ordered by logical clock and as all nodes have been on
        the pipeline forwarding m or it's ack, once P has received the
        acknowledgment for m, no new message will be able to go before m in the
        queue. Finally as all message will eventually be acknowledged, number of
        message before m in the queue will decrease. And after the reception of
        one ack, m will be the head of the queue and will be delivered.

        So if P broadcast a message m, he will eventually receive an ack
        for m and deliver it.
    \item No duplication: Each message are send and ack only once. As soon as a
        message is delivered it's removed from the pending queue, so it cannot
        be delivered again.
    \item No creation: No rules of the algorithm allow a process to
        create a message m without reveiving a broadcast request for m.
    \item Agreement: We have prooved that if P broadcast a message m
        then P will eventually receive an ack for m and deliver m, as
        the pipeline go throuh all the nodes and as a node deliver a
        message as soon as it acknowledge it, if P delivers m every node
        have delivered m.
    \item Total order: Let's imagine that two process p1 have delivered a message m1 then a
        message m2 and p2 have delivered m2 then m1. 
        
        As all the node's queues are sorted the same way we can consider that
        the \textit{good} order is the order of the queue, and we (empirically)
        state that this order is $m1<m2$.

        So if p2 has delivered m2 before m1, that means p2 had receive m2,
        delivered it, and then have received m1. Indeed if m1 have been received
        before m2 or if m1 and m2 have been in the queue at the same time, p2
        would have delivered m1 before m2.

        Either p2 is the last node of the pipeline used by m1, or p2 has
        received an ack for m1. In both cases, that mean when p2 is able to
        deliver m1, all the process have seen m1 and do the operation 
        \textit{clock=Max(clock(M1),MyClock)+1} before forwarding it or 
        sending an ack. If a process had send
        m2 with a clock smaller or equal to clock(m1), this message would have
        used the same path than m1 (or m1's ack) and as the link are FIFO, p2
        would have received m2 before m1. This contradict the hypothesis so two
        process can't deliver two message in a different order.

        The total order property is true !

\end{itemize}
\label{sec:pipelineack-proof}


\subsubsection*{Latency}
% TODO
The algorithm is based on the pipeline broadcast, if we have $N$ nodes, it takes
$N-1$ round for one broadcast. But as the last node of the pipeline start a
broadcast of acknowledgment, and as we wait for these ack to deliver the
message, the message is delivered by all the nodes only after $2(N-1)$ rounds.

As the pipeline is perfectly parallel, the latency will always be $2(N-1)$.
\subsubsection*{Throughput}
Let’s consider a system with N nodes that wishes to broadcast a message concurrently
We wish to know how long this will take to all N broadcasts to
complete.

All the nodes will spread through different pipeline and in $2(N-1)$ rounds, all the
nodes will have received all the messages and all the acks, so in $2(N-1)$ rounds,
every node is able to deliver every message in it's queue.

Finally, it take $2(N-1)$ rounds to broadcast $N$ messages, so we have a throughput
of $\frac{N}{2(N-1)}\longrightarrow_{N \rightarrow \infty}\frac{1}{2}$ which is totally independent of the number of
messages !
\subsection{Empirical analysis}
% TODO

\subsubsection*{Latency}
% TODO
Test nb nodes variant always 2(N-1) rounds for one broadcast, example on 8
nodes:
\begin{verbatim}
./Broadcast -R 20 -T -N 8 < ../testings/test-unic-broadcast 
Starting round 0
Enter an external events (format "start" or "n event")
Event added, enter an other event or "start"
event received 0 broadcast
Starting round 1
Enter an external events (format "start" or "n event")
1 0 hello received by 1 from 0 but not delivered yet
Starting round 2
Enter an external events (format "start" or "n event")
1 0 hello received by 2 from 1 but not delivered yet
Starting round 3
Enter an external events (format "start" or "n event")
1 0 hello received by 3 from 2 but not delivered yet
Starting round 4
Enter an external events (format "start" or "n event")
1 0 hello received by 4 from 3 but not delivered yet
Starting round 5
Enter an external events (format "start" or "n event")
1 0 hello received by 5 from 4 but not delivered yet
Starting round 6
Enter an external events (format "start" or "n event")
1 0 hello received by 6 from 5 but not delivered yet
Starting round 7
Enter an external events (format "start" or "n event")
1 0 hello received by 7 from 6 but not delivered yet
message delivered : 1 0 hello sender : 6 on node 7
Starting round 8
Enter an external events (format "start" or "n event")
1 0 ack received by 6 from 7 
message delivered : 1 0 hello sender : 5 on node 6
Starting round 9
Enter an external events (format "start" or "n event")
1 0 ack received by 5 from 6 
message delivered : 1 0 hello sender : 4 on node 5
Starting round 10
Enter an external events (format "start" or "n event")
1 0 ack received by 4 from 5 
message delivered : 1 0 hello sender : 3 on node 4
Starting round 11
Enter an external events (format "start" or "n event")
1 0 ack received by 3 from 4 
message delivered : 1 0 hello sender : 2 on node 3
Starting round 12
Enter an external events (format "start" or "n event")
1 0 ack received by 2 from 3 
message delivered : 1 0 hello sender : 1 on node 2
Starting round 13
Enter an external events (format "start" or "n event")
1 0 ack received by 1 from 2 
message delivered : 1 0 hello sender : 0 on node 1
Starting round 14
Enter an external events (format "start" or "n event")
1 0 ack received by 0 from 1 
message delivered : 1 0 hello sender : 0 on node 0
Starting round 15
Enter an external events (format "start" or "n event")
\end{verbatim}
\subsubsection*{Throughput}
% TODO

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Conclusion}
In this report we presented our implementation of a single-threaded,
round-based network simulator. We later used it to implement and reason about
two total-order broadcast protocols that we designed.

One of them achieved a latency of $\lceil\log_2(N)\rceil + 1$ which is close
to the optimal latency that one can achieve with a broadcast protocol where no
total-order is required.

The second protocol achieves a throughput of $1/2$ which is only half the
optimal for a broadcast protocol, but it's the price to pay to achieve a total
order. Moreover this result is independent from the number of message which mean
that performances won't decrease when we will want to send a lot of messages.

An interesting future work would be to try to determine if there exists a
total-order broadcast protocol that achieves an optimal latency of
$\lceil\log_2(N)\rceil$, or a protocol that achieve a better throughput than
the second protocol presented in this report.

\end{document}


%%%% Tasks
% Task 1: Design a network simulator
%   * Single thread
%   * Round based
%   * Any programming language
%   * N processes (machines)
%   * No crash
%   * Each machine sends (up to) one message at the begining of a round
%   * Each machine can receive (up to) one message at the end of a round
%
% Task 2: Check the behaviour of the simulator using the broadcast protocols
%         from the lectures.
%   * Basic (Latency = 3, Throughput = 1/3)
%   * Trees (Latency = 2, Throughput = 1/2)
%   * Pipe-line (Latency = 3, Throughput = 1)
%
% Tack 3: Design / Implement two regular total-order broadcast protocols
%   * Assumptions: No crash, perfect link, infinite memory, perfect failure
%                  detector
%   * First protocol: good latency
%   * Second protocol: good throughput (with N senders)
%
% Task 4: Write a report (10 to 15 pages)
%   * Description of simulator architecture
%   * Description of the two protocols
%   * Theoretical analysis of the two protocols (latency, throughput)
%   * Empirical evaluation of the two protocols (using the simulator)

